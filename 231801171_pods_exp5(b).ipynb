{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSMS_uNot1-o",
        "outputId": "420ed39e-a2e9-4ff0-f00c-683eaf4410fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, string, nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from nltk.tree import Tree\n",
        "\n",
        "for pkg in [\"punkt\",\"stopwords\",\"averaged_perceptron_tagger\",\"maxent_ne_chunker\",\"words\"]:\n",
        "    nltk.download(pkg, quiet=True)\n"
      ],
      "metadata": {
        "id": "voZlMgDGucdC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Reviews.csv\")\n",
        "reviews = df['Text'].dropna().sample(10000, random_state=42).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "_xPsDyFyu4Vs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tbl = str.maketrans('', '', string.punctuation)\n",
        "def preprocess(s): return s.lower().translate(tbl)\n",
        "reviews_clean = reviews.apply(preprocess)\n"
      ],
      "metadata": {
        "id": "6kNDyvlrvHnd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "def tokenize(text):\n",
        "    return [w for w in word_tokenize(text) if w.isalpha() and w not in stop]\n",
        "tokens = reviews_clean.apply(tokenize)\n"
      ],
      "metadata": {
        "id": "pj-kqyHWvK1E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = tokens.apply(pos_tag)\n",
        "print(\"POS sample:\", pos_tags.iloc[0][:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH54bDchvNt8",
        "outputId": "8464c369-502e-45c2-ccb6-fd01a861406b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS sample: [('tried', 'JJ'), ('couple', 'NN'), ('brands', 'NNS'), ('glutenfree', 'VBP'), ('sandwich', 'JJ'), ('cookies', 'NNS'), ('best', 'JJS'), ('bunch', 'NN'), ('theyre', 'NN'), ('crunchy', 'NN'), ('true', 'JJ'), ('texture', 'NN'), ('real', 'JJ'), ('cookies', 'NNS'), ('arent', 'VBP'), ('glutenfree', 'JJ'), ('might', 'MD'), ('think', 'VB'), ('filling', 'VBG'), ('makes', 'VBZ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker_tab')\n",
        "def extract_entities_from_pos(tagged):\n",
        "    tree = ne_chunk(tagged, binary=False)\n",
        "    ents = []\n",
        "    for node in tree:\n",
        "        if isinstance(node, Tree):\n",
        "            label = node.label()\n",
        "            text = \" \".join(w for w,_ in node.leaves())\n",
        "            ents.append((text, label))\n",
        "    return ents\n",
        "\n",
        "N = 200\n",
        "ner_per_review = [extract_entities_from_pos(pos_tags.iloc[i]) for i in range(min(N, len(pos_tags)))]\n",
        "flat_entities = [e for sub in ner_per_review for e in sub]\n",
        "entities_df = pd.DataFrame(flat_entities, columns=[\"entity\",\"label\"])\n",
        "print(entities_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OYDcfYcvXlU",
        "outputId": "f00790c0-167d-4175-c392-6debe9057101"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [entity, label]\n",
            "Index: []\n"
          ]
        }
      ]
    }
  ]
}